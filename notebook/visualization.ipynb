{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative analysis of divergent association scores in humans and GPT-3.5turbo and GPT-4\n",
    "Table of content**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..') \n",
    "from scripts import dat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats \n",
    "from scripts.multiple_test import analyze_results, create_heatmap, most_common_words, create_bar_plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "colors = {'GPT3_low_DAT': '#FDB813',\n",
    "          'GPT3_mid_DAT':'#EF6C00',\n",
    "          'GPT3_high_DAT': '#D32F2F',\n",
    "          'GPT3_low_control': '#EEE8AA',\n",
    "          'GPT3_mid_control': '#FFE082',\n",
    "          'GPT3_high_control':'#FFAB91',\n",
    "          'GPT4_low_DAT':'#00B7C3',\n",
    "          'GPT4_mid_DAT':'#3F51B5',\n",
    "          'GPT4_high_DAT':'#9C27B0',\n",
    "          'GPT4_low_control':'#80DEEA',\n",
    "          'GPT4_mid_control':'#8C9EFF',\n",
    "          'GPT4_high_control':'#CE93D8',\n",
    "          'Human (8k)':'black',\n",
    "          'Human (750k)':'darkgrey',\n",
    "          'GPT3_mid_ety': '#26A69A',\n",
    "          'GPT3_mid_thes': '#D81B60',\n",
    "          'GPT3_mid_opp': '#FFEE58',\n",
    "          'GPT3_mid_rnd':'#7E57C2',\n",
    "          'GPT4_mid_ety': '#1A7466',\n",
    "          'GPT4_mid_thes': '#A51645',\n",
    "          'GPT4_mid_opp': '#BBA600',\n",
    "          'GPT4_mid_rnd':'#4A3280',\n",
    "          'BARD_mid_DAT':'peru',\n",
    "          'BARD_mid_control':'#DEC3A3',\n",
    "          'CLAUDE_low_DAT':'#FDB813',\n",
    "          'CLAUDE_mid_DAT':'teal',\n",
    "          'CLAUDE_high_DAT':'#D32F2F',\n",
    "          'CLAUDE_mid_control':'#1ACCCC',\n",
    "          'PYTHIA_mid_DAT':'#603080',\n",
    "          'PYTHIA_mid_control':'#BF9FDF',\n",
    "          'StableLM_mid_DAT':'darkgreen',\n",
    "          'StableLM_mid_control':'#80FF80',\n",
    "          'StableLMoass_mid_DAT':'deeppink',\n",
    "          'StableLMoass_mid_control':'pink',\n",
    "          'RedPajama_mid_DAT':'#FF0000',\n",
    "          'RedPajama_mid_control':'#FF8080',\n",
    "          'Vicuna_mid_DAT':'#7BC8F6',\n",
    "          'Vicuna_mid_control':'#ADD8E6',\n",
    "          'Vicuna_mid_ety':'#7BC8F6',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distributions(colors_, spacing=5):\n",
    "    x = np.linspace(-10, 10 + len(colors_) * spacing, 1000)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for i, (key, color) in enumerate(colors_.items()):\n",
    "        mean = i * spacing\n",
    "        y = stats.norm.pdf(x, loc=mean, scale=1)\n",
    "        plt.plot(x, y, color=color, label=key)\n",
    "        plt.fill_between(x, y, color=color, alpha=0.3)\n",
    "        \n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.1)\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Density')\n",
    "    plt.title('Standard Normal Distributions with Incrementing Mean Values')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plot_distributions(colors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data and model\n",
    "### Divergent association task model\n",
    "description of the model and Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe model from https://nlp.stanford.edu/projects/glove/\n",
    "model_dat = dat.Model(\"../model/glove.840B.300d.txt\", \"words.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human data\n",
    "* Olson and coll. (2021) data - ~8k\n",
    "* DAT website data harvest - 750k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DAT Olson's data\n",
    "filename = \"../human_data_dat/study2.tsv\"\n",
    "\n",
    "# read the data into a DataFrame\n",
    "df_human = pd.read_csv(filename, sep='\\t')\n",
    "\n",
    "# extract the \"dat\" column as a list of floats\n",
    "dat_study = df_human['dat'].astype(float).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DAT big data file\n",
    "global_crea = pd.read_csv('../human_data_dat/global-creativity.csv')\n",
    "DAT_bigdata = global_crea['score']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch machine data\n",
    "* GPT-3.5turbo\n",
    "* GPT-4\n",
    "\n",
    "1. Glob all data files (`.json`).\n",
    "2. Iterate through samples.\n",
    "3. Split the tokens and keep only the words.\n",
    "4. Define strategy used from filename.\n",
    "5. Define temperature level from filename.\n",
    "6. Define model from filename\n",
    "7. Compute DAT score for the given sample of 10 words. (DAT model computes pairwise semantic distances)\n",
    "8. Store result as a row in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_with_stars(input_list):\n",
    "    pattern = r'\\*\\*(\\w+)\\*\\*'\n",
    "    words_with_stars = []\n",
    "\n",
    "    for string in input_list:\n",
    "        matches = re.findall(pattern, string)\n",
    "        if matches:\n",
    "            words_with_stars.extend(matches)\n",
    "\n",
    "    return words_with_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where the data is located\n",
    "data_path = '../machine_data_dat/'\n",
    "\n",
    "# Define a dictionary to store the results of model.dat(words)\n",
    "results_dict = {'Temperature': [], 'Strategy': [], 'Score': [], 'Model': [], 'Control': [], 'Words': []}\n",
    "\n",
    "# keep track of these so that we can apply further methods of words extractions\n",
    "bard_data = []\n",
    "pythia_data = []\n",
    "\n",
    "# define counters\n",
    "counter_bard = 0\n",
    "counter_pythia = 0\n",
    "counter_gpt3 = 0\n",
    "counter_gpt4 = 0\n",
    "counter_claude = 0\n",
    "counter_stablelm = 0\n",
    "counter_stablelmoasst = 0\n",
    "counter_red = 0\n",
    "counter_vicuna = 0\n",
    "\n",
    "# Loop through each file in the data path\n",
    "for file in sorted(glob.glob('../machine_data_dat/*.json')):\n",
    "    # Open the file and load the JSON data\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    file = os.path.basename(file)\n",
    "    # Loop through each key in the JSON data\n",
    "    for i in data.keys():\n",
    "        # Split the words into a list\n",
    "        words = data[i].split()\n",
    "        if 'bard' in file:\n",
    "            words = extract_words_with_stars(words)\n",
    "            bard_data.append(words)\n",
    "        else:\n",
    "            # Find the indices of '1.' to '10.'\n",
    "            indices = [m.start() for m in re.finditer(r'\\b(?:[1-9]|10)\\.', data[i])]  \n",
    "\n",
    "            # Extract the words after '1.' to '10.' and store them in a new list\n",
    "            new_words = []\n",
    "            for idx in range(len(indices)):\n",
    "                if idx < len(indices) - 1:\n",
    "                    new_words.append(data[i][indices[idx] + 3:indices[idx + 1]].strip())\n",
    "                else:\n",
    "                    new_words.append(data[i][indices[idx] + 3:].strip())\n",
    "\n",
    "            words = new_words\n",
    "        \n",
    "        # Define the strategy based on the file name\n",
    "        if 'sample_thes' in file or 'gpt4_thes' in file:\n",
    "            strategy = 'Thesaurus'\n",
    "        elif 'sample_oppo' in file or 'gpt4_oppo' in file:\n",
    "            strategy = 'Opposition'\n",
    "        elif 'ety' in file:\n",
    "            strategy = 'Etymology'\n",
    "        elif 'sample_rand' in file:\n",
    "            strategy = 'Random'\n",
    "        elif 'none' in file:\n",
    "            strategy = 'Original instructions'\n",
    "        elif 'nothing' in file:\n",
    "            strategy = 'Control'\n",
    "        else:\n",
    "            strategy = 'Original instructions'\n",
    "        # Define the temperature based on the file name\n",
    "        if 'temp1.5' in file:\n",
    "            condition = 'High'\n",
    "        elif 'temp0.5' in file:\n",
    "            condition = 'Low'\n",
    "        elif 'temp1.0' in file:\n",
    "            condition = 'Mid'\n",
    "        elif 'temp0.7' in file or \"temp0.8\" in file:\n",
    "            condition = 'Mid'\n",
    "        elif 'temp0.2' in file:\n",
    "            condition = 'Low'\n",
    "        elif 'temp0.9' in file:\n",
    "            condition = 'High'\n",
    "        elif 'temp1.0' and 'pythia' in file:\n",
    "            condition = 'High'\n",
    "        elif 'temp1.2' and 'claude' in file:\n",
    "            condition = 'High'\n",
    "        else:\n",
    "            condition = 'Mid'\n",
    "        \n",
    "        # Define the model based on the file name\n",
    "        if 'gpt4' in file:\n",
    "            llm = 'GPT4'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_gpt4 += 1\n",
    "        elif 'claude' in file:\n",
    "            llm = 'CLAUDE'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_claude += 1\n",
    "        elif 'bard' in file:\n",
    "            llm = 'BARD'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_bard += 1\n",
    "        elif 'pythia' in file:\n",
    "            llm = 'PYTHIA'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_pythia += 1\n",
    "        elif 'oasst_stablelm' in file:\n",
    "            llm = 'StableLM-oasst'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_stablelmoasst += 1\n",
    "        elif 'stablelm' in file:\n",
    "            llm = 'StableLM'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_stablelm += 1\n",
    "        elif 'red' in file:\n",
    "            llm='RedPajama'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_red += 1\n",
    "        elif 'vicuna' in file:\n",
    "            llm = 'Vicuna'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_vicuna += 1\n",
    "        else:\n",
    "            llm = 'GPT3'\n",
    "            if condition == 'Mid' and strategy == 'Original instructions':\n",
    "                counter_gpt3 += 1\n",
    "        \n",
    "        # Loop through each word in the list\n",
    "        score = model_dat.dat(words)\n",
    "            \n",
    "        # Append the results to the dictionary\n",
    "        results_dict['Temperature'].append(condition)\n",
    "        results_dict['Strategy'].append(strategy)\n",
    "        results_dict['Score'].append(score)\n",
    "        results_dict['Words'].append(words)\n",
    "        results_dict['Model'].append(llm)\n",
    "        # Add a columns with binary Control vs. experimental\n",
    "        if strategy == 'Control':\n",
    "            results_dict['Control'].append('Control')\n",
    "        elif strategy == 'Original instructions':\n",
    "            results_dict['Control'].append('Original instructions')\n",
    "        else:\n",
    "            results_dict['Control'].append('Strategy')\n",
    "\n",
    "# Convert the results dictionary to a Pandas DataFrame\n",
    "results_df = pd.DataFrame(results_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate all human and machine data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the website data with the results DataFrame\n",
    "results_df = pd.concat([results_df, pd.DataFrame({'Temperature': np.tile(None, len(DAT_bigdata)),\n",
    "                                                  'Strategy': np.tile('Original instructions', len(DAT_bigdata)),\n",
    "                                                  'Score': np.array(DAT_bigdata),\n",
    "                                                  'Model': np.tile('Human (750k)', len(DAT_bigdata)),\n",
    "                                                  'Control': np.tile('Original instructions', len(DAT_bigdata))})])\n",
    "# concat with study data\n",
    "results_df = pd.concat([results_df, pd.DataFrame({'Temperature': np.tile(None, len(dat_study)),\n",
    "                                                  'Strategy': np.tile('Original instructions', len(dat_study)),\n",
    "                                                  'Score': np.array(dat_study),\n",
    "                                                  'Model': np.tile('Human (8k)', len(dat_study)),\n",
    "                                                  'Control': np.tile('Original instructions', len(dat_study))})])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save all machine and human data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('concatenated_results.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quality control manipulations\n",
    "## Most common words in humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "n_words = 5  # Set the number of most common words to find\n",
    "\n",
    "# Concatenate all the words from columns 'word.1' to 'word.10'\n",
    "all_words = df_human.loc[:, 'word.1':'word.10'].values.flatten()\n",
    "\n",
    "# Count the occurrences of each word\n",
    "word_counter = collections.Counter(all_words)\n",
    "\n",
    "# Find the n most common words\n",
    "most_common_words_humans = word_counter.most_common(n_words)\n",
    "\n",
    "# Calculate the percentage of occurrences for each of the n most common words\n",
    "total_words = len(all_words)\n",
    "most_common_words_percentage = [(word, count / total_words * 1000) for word, count in most_common_words_humans]\n",
    "\n",
    "# Print the n most common words with their percentages\n",
    "print(f\"Top {n_words} most common words with their percentage of occurrence:\")\n",
    "for word, percentage in most_common_words_percentage:\n",
    "    print(f\"{word}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize adherence to instructions in machines\n",
    "Using the ratio of the number of responses that have been harvested vs. number of responses on which DAT scores were computed as a measure of the level attrition in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counting = {\"BARD\":counter_bard, \"PYTHIA\":counter_pythia, \"GPT3\":counter_gpt3, \"GPT4\": counter_gpt4, \"CLAUDE\": counter_claude, \"StableLM\": counter_stablelm, \"StableLM-oasst\": counter_stablelmoasst, \"RedPajama\":counter_red, \"Vicuna\": counter_vicuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "import seaborn as sns\n",
    "\n",
    "# Extract data\n",
    "data = {}\n",
    "mean_scores = {}\n",
    "for model in results_df[\"Model\"].unique():\n",
    "    # these were not used\n",
    "    if \"Human\" in model or \"StableLM-oasst\" in model:\n",
    "        continue\n",
    "    temp_df = results_df.loc[(results_df[\"Model\"] == model) &\n",
    "                             (results_df[\"Strategy\"]==\"Original instructions\") &\n",
    "                             (results_df[\"Temperature\"]==\"Mid\")].dropna()\n",
    "    # ratio for the given model\n",
    "    data[model] = len(temp_df) / counting[model]\n",
    "    mean_scores[model] = temp_df[\"Score\"].mean(skipna=True)\n",
    "\n",
    "# Sort data by mean score\n",
    "data = dict(sorted(data.items(), key=lambda x: mean_scores[x[0]], reverse=False))\n",
    "\n",
    "# Plot bar chart\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "sns.barplot(x=list(data.keys()), y=list(data.values()), palette=[colors[model+\"_mid_DAT\"] for model in data.keys()], ax=ax, width=.9)\n",
    "sns.despine(left=True, bottom=True)\n",
    "ax.set_ylabel(\"Proportion of fluent responses\")\n",
    "ax.set_title(\"Fluent responses by model (Original instructions, Temperature: Mid)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_ = {\n",
    "    'GPT4': '#3F51B5',\n",
    "    'GPT3': '#EF6C00',\n",
    "    'CLAUDE': 'teal',\n",
    "    'PYTHIA': '#603080',\n",
    "    'StableLM': 'darkgreen',\n",
    "    'BARD': 'peru',\n",
    "    'RedPajama': 'tomato',\n",
    "    'Vicuna': '#7BC8F6',\n",
    "}\n",
    "\n",
    "# Add the human data\n",
    "human_data = [(\"Dog\", 8.38), (\"Tree\", 9.40), (\"Car\", 11.68)]\n",
    "model_word_counts = []\n",
    "\n",
    "# Assuming results_df is already loaded\n",
    "model_names = list(colors_.keys())\n",
    "\n",
    "n_words = 3\n",
    "\n",
    "# Iterate over all models and accumulate the word counts\n",
    "for model_name in model_names:  # Exclude the last model_name, \"Human\"\n",
    "    temp = 'Mid'\n",
    "    strategy = 'Original instructions'\n",
    "\n",
    "    df = results_df.loc[(results_df['Model'] == model_name) & (results_df['Strategy'] == strategy) &\n",
    "                        (results_df['Temperature'] == temp)].dropna()\n",
    "\n",
    "    all_words = df['Words'].tolist()\n",
    "    n_lists = len(all_words)\n",
    "    all_words = [word for sublist in all_words for word in sublist]\n",
    "\n",
    "    word_counts = most_common_words(all_words, n_words)\n",
    "    word_counts_percentage = [(word, count / len(all_words) * 10 * 100) for word, count in word_counts]\n",
    "    model_word_counts.append(sorted(word_counts_percentage, key=lambda x: x[1], reverse=False))\n",
    "\n",
    "# Add the human data to model_word_counts\n",
    "model_word_counts.append(human_data)\n",
    "\n",
    "# Create the horizontal bar plot\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "bar_width = 0.50\n",
    "bar_positions = [i for i in range(n_words * len(model_names))]\n",
    "\n",
    "for i, (model_name, word_counts) in enumerate(zip(model_names, model_word_counts)):\n",
    "    word_labels, counts = zip(*word_counts)\n",
    "    for j, (word, count) in enumerate(zip(word_labels, counts)):\n",
    "        ax.barh(bar_positions[i * n_words + j], count, bar_width, color=colors_[model_name])\n",
    "        ax.text(count + 1, bar_positions[i * n_words + j], word, va='center')\n",
    "# set model names\n",
    "ax.set_yticks([(i * n_words) + n_words / 2 for i in range(len(model_names))])\n",
    "ax.set_yticklabels(model_names)\n",
    "# axes names\n",
    "ax.set_xlabel('Frequency (%)')\n",
    "ax.set_title('Top 3 words for each model', fontsize=16)\n",
    "ax.set_xlim(0, 80)\n",
    "# remove box frame\n",
    "ax.spines['top'].set_visible(False)\n",
    "# remove right frame\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{'_'.join(model_names)}_top{n_words}_words_percentage.png\", dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'Vicuna'\n",
    "temp = 'Mid'\n",
    "strategy = 'Etymology'\n",
    "palette = 'Accent'\n",
    "n_words = 10\n",
    "\n",
    "df = results_df.loc[(results_df['Model']==modelname) & (results_df['Strategy']==strategy ) &\n",
    "                    ((results_df['Temperature']==temp))].dropna()\n",
    "\n",
    "# Use explode to create a new row for each word\n",
    "all_words = [word for word_list in df['Words'] for word in word_list]\n",
    "all_words = df['Words'].tolist()\n",
    "n_lists = len(all_words)\n",
    "all_words = [word for sublist in all_words for word in sublist]\n",
    "\n",
    "create_bar_plot(most_common_words(all_words, n_words), n_lists=n_lists, ylim=(0, 100), alpha=0.9, palette_name=palette,\n",
    "                save=False, modelname=modelname, temp=temp, strategy=strategy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Main analyses\n",
    "## Overall differences between human and machines\n",
    "figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FacetGrid object\n",
    "pal = [colors['GPT3_mid_DAT'],\n",
    "       colors['GPT4_mid_DAT'],\n",
    "       colors['CLAUDE_mid_DAT'],\n",
    "       colors['StableLM_mid_DAT'],\n",
    "       colors['Human (750k)'],\n",
    "       colors['BARD_mid_DAT'],\n",
    "       colors['PYTHIA_mid_DAT'],\n",
    "       colors['RedPajama_mid_DAT'],\n",
    "       colors['Vicuna_mid_DAT']]\n",
    "order = ['BARD', 'StableLM','RedPajama', 'PYTHIA', 'CLAUDE', 'Vicuna', 'GPT3', 'GPT4', 'Human (750k)']\n",
    "df = results_df.loc[(results_df['Strategy']=='Original instructions') &\n",
    "                    (results_df['Temperature']=='Mid') | (results_df['Temperature'].isnull())]\n",
    "\n",
    "df = df.groupby('Model').apply(lambda x: x[np.abs(x['Score'] - x['Score'].mean()) <= 3 * x['Score'].std()]).reset_index(drop=True)\n",
    "df = df.groupby('Model').apply(lambda x: x.sample(min(len(x), 500), random_state=32)).reset_index(drop=True)\n",
    "\n",
    "g = sns.FacetGrid(df, row=\"Model\", hue=\"Model\", aspect=9, height=1, palette=[pal[5], pal[2], pal[0], pal[1], pal[4], pal[8], pal[3], pal[6], pal[7]], row_order=order)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Score\",\n",
    "      bw_adjust=1, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    # check if Human is in the label\n",
    "    txt = f\"{label} ({len(df.loc[df['Model']==label])})\"\n",
    "    ax.text(0, .2, txt, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes,fontsize=16)\n",
    "g.map(label, \"Score\")\n",
    "mean_conf, pvals, tvals = analyze_results(df, 'Model', order)\n",
    "# Add vertical lines for mean and confidence intervals\n",
    "for ax, model in zip(g.axes.flat, order):\n",
    "    if model == 'Human (8k)':\n",
    "        print(mean_conf[mean_conf['Model'] == model]['median'])\n",
    "        ax.axvline(mean_conf[mean_conf['Model'] == model]['median'].values[0], color='white', linestyle='--', ymin=0, ymax=0.5)\n",
    "    else:\n",
    "        ax.axvline(mean_conf[mean_conf['Model'] == model]['median'].values[0], color='black', linestyle='--', ymin=0, ymax=0.5)\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "            ax.set_xlabel('Creativity score', fontsize=16)\n",
    "            for label in ax.get_xticklabels():\n",
    "                  label.set_fontsize(14)\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.tight_layout()\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.65)\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)\n",
    "g.set(xlim=(30, 100))\n",
    "#g.savefig('DAT_LLMs_humans_ridge_median_test')\n",
    "create_heatmap(mean_conf, 'Model', tvals_table=tvals, pvals_table=pvals,\n",
    "               pal=[pal[5], pal[3], pal[7], pal[6], pal[1], pal[8], pal[0], pal[2], pal[4]], order=order, xlim=(50,90), save='DAT_GPT_humans_models_test', large=(13, 6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control vs DAT\n",
    "figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from multiple_test import *\n",
    "list_of_dfs = [results_df.loc[(results_df['Model']=='GPT3') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='GPT4') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='CLAUDE') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='PYTHIA') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='BARD') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='StableLM') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='RedPajama') &\n",
    "                              (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],\n",
    "               results_df.loc[(results_df['Model']=='Vicuna') &\n",
    "                               (results_df['Temperature']=='Mid') &\n",
    "                              (results_df['Control']!='Strategy')],]\n",
    "\n",
    "for e, df in enumerate(list_of_dfs):\n",
    "      gpt = df[\"Model\"].unique()[0]\n",
    "      # Remove observations with more or less than 3 std, and then randomly sample up to 500 observations\n",
    "      df['Control'] = df['Control'].replace({'Original instructions': 'DAT'})\n",
    "      df = df.groupby('Control').apply(lambda x: x[np.abs(x['Score'] - x['Score'].mean()) <= 3 * x['Score'].std()]).reset_index(drop=True)\n",
    "      df = df.groupby('Control').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "            \n",
    "\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = [colors[f'{gpt}_mid_DAT'], colors[f'{gpt}_mid_control']]\n",
    "      order = ['Control', 'DAT']\n",
    "      g = sns.FacetGrid(df, row=\"Control\", hue=\"Control\", aspect=9, height=1, palette=[pal[1], pal[0]], row_order=order)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "      # txt = f\"{label} ({len(df.loc[df['Control']==label])})\"\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            txt = f\"{label}\"\n",
    "            ax.text(0, .2, txt, fontweight=\"bold\", color=color,\n",
    "                        ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "      # change title from the FaceGrid object\n",
    "      #g.set_titles(\"Stable LM\")\n",
    "      g.map(label, \"Score\")\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Control', order=order)\n",
    "      #print(mean_conf)\n",
    "      # Add vertical lines for mean and confidence intervals\n",
    "      for ax, model in zip(g.axes.flat, [0,1]):\n",
    "            ax.axvline(mean_conf['median'][model], color='black', linestyle='--')\n",
    "      # Set the subplots to overlap\n",
    "      for ax in g.axes.flat:\n",
    "            ax.set_xlabel('Creativity score', fontsize=16)\n",
    "            for label in ax.get_xticklabels():\n",
    "                  label.set_fontsize(14)\n",
    "      g.figure.subplots_adjust(hspace=-.47)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      # set the main title of the figure\n",
    "      \n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(20, 100))\n",
    "      g.fig.suptitle(df['Model'].unique()[0], fontsize=16)\n",
    "      g.fig.suptitle(gpt, fontsize=16)\n",
    "      g.savefig('DAT_GPT_control4_kde_{}'.format(str(e)), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Control', tvals_table=tvals, pvals_table=pvals, pal=reversed(pal), order=['Control', 'DAT'], \n",
    "                     save='DAT_GPT_control6_{}'.format(str(e)), large=(9, 4), xlim=(50,90), rotation=45, axis_name='Creativity score')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injecting strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_palette(model, order):\n",
    "    color_map = {\n",
    "        'GPT3': {\n",
    "            'Etymology': colors['GPT3_mid_ety'],\n",
    "            'DAT': colors['GPT3_mid_DAT'],\n",
    "            'Control': 'gold',\n",
    "            'Opposition': colors['GPT3_mid_control'],\n",
    "            'Random': colors['GPT3_mid_rnd'],\n",
    "            'Thesaurus': colors['GPT3_mid_thes']\n",
    "        },\n",
    "        'GPT4': {\n",
    "            'Etymology': colors['GPT4_mid_ety'],\n",
    "            'Control': colors['GPT4_mid_DAT'],\n",
    "            'DAT': colors['GPT4_mid_control'],\n",
    "            'Opposition': colors['GPT4_mid_opp'],\n",
    "            'Thesaurus': colors['GPT4_mid_thes']\n",
    "        },\n",
    "        'Vicuna': {\n",
    "            'Etymology': colors['Vicuna_mid_ety'],\n",
    "            'Control': colors['Vicuna_mid_control'],\n",
    "            'DAT': colors['Vicuna_mid_DAT'],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return [color_map[model][strategy] for strategy in order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PLOT STRATEGIES FOR GPT-3\n",
    "gpt = \"GPT3\"\n",
    "\n",
    "df = results_df.loc[(results_df['Model'] == gpt) & (results_df['Temperature'] == 'Mid')]\n",
    "df['Strategy'] = df['Strategy'].replace({'Original instructions': 'DAT'})\n",
    "df = df.groupby('Strategy').apply(lambda x: x[np.abs(x['Score'] - x['Score'].mean()) <= 3 * x['Score'].std()]).reset_index(drop=True)\n",
    "df = df.groupby('Strategy').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "df = df[df['Strategy'] != 'Random']\n",
    "\n",
    "order = df.groupby('Strategy')['Score'].mean().sort_values(ascending=True).index\n",
    "pal_order = get_palette(gpt, order)\n",
    "# Initialize the FacetGrid gpt\n",
    "g = sns.FacetGrid(df,row=\"Strategy\", hue=\"Strategy\", aspect=9,\n",
    "                  height=1, palette=[pal_order[0], pal_order[3], pal_order[1], pal_order[2],pal_order[4]], row_order=order)\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Score\",\n",
    "      bw_adjust=1, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "      ax = plt.gca()\n",
    "      ax.text(0, .2, f\"{label}\", fontweight=\"bold\", color=color,\n",
    "                  ha=\"left\", va=\"center\", transform=ax.transAxes, fontsize=16)\n",
    "g.map(label, \"Score\")\n",
    "# Add vertical lines for mean and confidence intervals\n",
    "mean_conf, pvals, tvals = analyze_results(df, 'Strategy', order=order)\n",
    "for ax, model in zip(g.axes.flat, order):\n",
    "      ax.axvline(mean_conf[mean_conf['Strategy'] == model]['median'].values[0], color='black', linestyle='--', ymin=0, ymax=0.5)\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('Creativity score', fontsize=16)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(16)\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.32)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.set(xlim=(35, 100))\n",
    "g.despine(bottom=True, left=True)\n",
    "g.savefig('GPT3_strategy3_kde.png', dpi=300)\n",
    "'''create_heatmap(mean_conf, 'Strategy', tvals_table=tvals,\n",
    "            pvals_table=pvals, order=order, pal=pal_order, color_order=[pal_order[2], pal_order[0], pal_order[5], pal_order[3],pal_order[4], pal_order[1]], large=17, xlim=(50, 90),\n",
    "            save='GPT_strategy2_{}.png'.format(e))'''\n",
    "create_heatmap(mean_conf, 'Strategy', tvals_table=tvals,\n",
    "            pvals_table=pvals, order=order, pal=pal_order, color_order=[pal_order[2], pal_order[0], pal_order[4],pal_order[3], pal_order[1]], large=(10.5, 5), xlim=(50, 90),\n",
    "            save='GPT3_final', rotation=45, title_name='Performance by strategy', axis_name='Creativity score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PLOT STRATEGIES FOR GPT-4\n",
    "\n",
    "gpt = \"GPT4\"\n",
    "\n",
    "df = results_df.loc[(results_df['Model'] == gpt) & (results_df['Temperature'] == 'Mid')]\n",
    "df['Strategy'] = df['Strategy'].replace({'Original instructions': 'DAT', 'Control': 'Control'})\n",
    "df_all = df.copy()\n",
    "\n",
    "#df_all['Strategy'] = df_all['Strategy'].replace({'Original instructions': 'DAT', 'Control': 'Random (Control)'})\n",
    "df_all = df_all.groupby('Strategy').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "df = df.groupby('Strategy').apply(lambda x: x[np.abs(x['Score'] - x['Score'].mean()) <= 3 * x['Score'].std()]).reset_index(drop=True)\n",
    "df = df.groupby('Strategy').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "order = df.groupby('Strategy')['Score'].mean().sort_values(ascending=True).index\n",
    "pal_order = get_palette(gpt, order)\n",
    "\n",
    "# Initialize the FacetGrid gpt\n",
    "g = sns.FacetGrid(df,row=\"Strategy\", hue=\"Strategy\", aspect=9,\n",
    "                  height=1, palette=[pal_order[2], pal_order[1], pal_order[0], pal_order[3],pal_order[4]], row_order=order,\n",
    "                  )\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Score\",\n",
    "      bw_adjust=1, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "# f\"{label} ({len(df.loc[df['Strategy']==label])})\"\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "      ax = plt.gca()\n",
    "      ax.text(0, .2, f\"{label}\", fontweight=\"bold\", color=color,\n",
    "                  ha=\"left\", va=\"center\", transform=ax.transAxes, fontsize=16)\n",
    "g.map(label, \"Score\")\n",
    "# Add vertical lines for mean and confidence intervals\n",
    "mean_conf, pvals, tvals = analyze_results(df_all, 'Strategy', order=order)\n",
    "for ax, model in zip(g.axes.flat, order):\n",
    "      ax.axvline(mean_conf[mean_conf['Strategy'] == model]['median'].values[0], color='black', linestyle='--', ymin=0, ymax=0.5)\n",
    "\n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.32)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.set(xlim=(35, 100))\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('Creativity score', fontsize=16)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(16)\n",
    "\n",
    "g.despine(bottom=True, left=True)\n",
    "\n",
    "g.savefig('GPT4_strategy_kde_final_.png', dpi=300)\n",
    "create_heatmap(mean_conf, 'Strategy', tvals_table=tvals,\n",
    "            pvals_table=pvals, order=order, pal=pal_order, color_order=[pal_order[3], pal_order[2], pal_order[1],pal_order[4], pal_order[0]], large=(10.5, 5), xlim=(50, 90),\n",
    "            save='GPT4_strategy_final.png', rotation=45, title_name='Performance by strategy', axis_name='Creativity score')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PLOT STRATEGIES FOR Vicuna\n",
    "\n",
    "df = results_df.loc[(results_df['Model'] == 'Vicuna') & (results_df['Temperature'] == 'Mid')]\n",
    "df['Strategy'] = df['Strategy'].replace({'Original instructions': 'DAT', 'Control': 'Control'})\n",
    "df_all = df.copy()\n",
    "\n",
    "df_all = df_all.groupby('Strategy').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "df = df.groupby('Strategy').apply(lambda x: x[np.abs(x['Score'] - x['Score'].mean()) <= 3 * x['Score'].std()]).reset_index(drop=True)\n",
    "df = df.groupby('Strategy').apply(lambda x: x.sample(min(len(x), 500), random_state=42)).reset_index(drop=True)\n",
    "\n",
    "order = df.groupby('Strategy')['Score'].mean().sort_values(ascending=True).index\n",
    "pal_order = get_palette(gpt, order)\n",
    "\n",
    "# Initialize the FacetGrid gpt\n",
    "g = sns.FacetGrid(df,row=\"Strategy\", hue=\"Strategy\", aspect=9,\n",
    "                  height=1, palette=[pal_order[0], pal_order[1], pal_order[2]], row_order=order,\n",
    "                  )\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"Score\",\n",
    "      bw_adjust=1, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "# passing color=None to refline() uses the hue mapping\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "# f\"{label} ({len(df.loc[df['Strategy']==label])})\"\n",
    "# Define and use a simple function to label the plot in axes coordinates\n",
    "def label(x, color, label):\n",
    "      ax = plt.gca()\n",
    "      ax.text(0, .2, f\"{label}\", fontweight=\"bold\", color=color,\n",
    "                  ha=\"left\", va=\"center\", transform=ax.transAxes, fontsize=16)\n",
    "g.map(label, \"Score\")\n",
    "# Add vertical lines for mean and confidence intervals\n",
    "mean_conf, pvals, tvals = analyze_results(df_all, 'Strategy', order=order)\n",
    "for ax, model in zip(g.axes.flat, order):\n",
    "      ax.axvline(mean_conf[mean_conf['Strategy'] == model]['median'].values[0], color='black', linestyle='--', ymin=0, ymax=0.5)\n",
    "      \n",
    "# Set the subplots to overlap\n",
    "g.figure.subplots_adjust(hspace=-.32)\n",
    "\n",
    "# Remove axes details that don't play well with overlap\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.set(xlim=(35, 100))\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.set_xlabel('Creativity score', fontsize=16)\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_fontsize(16)\n",
    "\n",
    "g.despine(bottom=True, left=True)\n",
    "\n",
    "g.savefig('GPT4_strategy_kde_final_.png', dpi=300)\n",
    "create_heatmap(mean_conf, 'Strategy', tvals_table=tvals,\n",
    "            pvals_table=pvals, order=order, pal=pal_order, color_order=[pal_order[1], pal_order[0], pal_order[2]], large=(10.5, 5), xlim=(50, 90),\n",
    "            save='GPT4_strategy_final.png', rotation=45, title_name='Performance by strategy', axis_name='Creativity score')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of temperature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_filter_std_n(group):\n",
    "    group_filtered = group[np.abs(group['Score'] - group['Score'].mean()) <= 3 * group['Score'].std()]\n",
    "    return group_filtered.sample(min(len(group_filtered), 500), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [results_df.loc[(results_df['Model']=='GPT4') & \n",
    "                              (results_df['Control']=='Control')],\n",
    "               results_df.loc[(results_df['Model']=='GPT4') &\n",
    "                              (results_df['Control']=='Original instructions')]]\n",
    "conditions = ['Low', 'Mid', 'High']\n",
    "list_of_dfs_normalized_filtered = [df.groupby('Temperature', as_index=False).apply(normalize_filter_std_n) for df in list_of_dfs]\n",
    "for e, df in enumerate(list_of_dfs_normalized_filtered):\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = sns.color_palette('CMRmap',n_colors=3, desat=.9)\n",
    "      # keep color order consistent\n",
    "      pal = [pal[1], pal[0], pal[2]]\n",
    "      g = sns.FacetGrid(df, row=\"Temperature\", hue=\"Temperature\", aspect=9, height=1, palette=pal, row_order=conditions)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            ax.text(0, .2, f\"{label}\",\n",
    "                    fontweight=\"bold\", color=color,ha=\"left\", va=\"center\",\n",
    "                    transform=ax.transAxes)\n",
    "      g.map(label, \"Score\")\n",
    "       # Add vertical lines for mean and confidence intervals\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Temperature', order=conditions)\n",
    "      for ax, model in zip(g.axes.flat, ['Low', 'Mid', 'High']):\n",
    "            ax.axvline(mean_conf[mean_conf['Temperature'] == model]['median'].values[0], color='black', linestyle='--')\n",
    "\n",
    "      # Set the subplots to overlap\n",
    "      g.figure.subplots_adjust(hspace=-.5)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(30, 100))\n",
    "      \n",
    "      # Set a title for the figure\n",
    "      g.fig.suptitle(f\"GPT-4 - {df['Control'].unique()[0]}\", fontsize=20, y=1.05)\n",
    "      g.savefig('GPT_DAT_temperature2_kde{}.png'.format(e), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Temperature', tvals_table=tvals, pvals_table=pvals, pal=[pal[1], pal[2], pal[0]], order=['Low', 'Mid', 'High'],\n",
    "                     save='GPT_DAT_temperature3_{}.png'.format(e), large=(7, 3.5), xlim=(60, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [results_df.loc[(results_df['Model']=='CLAUDE') &\n",
    "                              (results_df['Control']=='Original instructions')]]\n",
    "conditions = ['Low', 'Mid', 'High']\n",
    "list_of_dfs_normalized_filtered = [df.groupby('Temperature', as_index=False).apply(normalize_filter_std_n) for df in list_of_dfs]\n",
    "for e, df in enumerate(list_of_dfs_normalized_filtered):\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = sns.color_palette('CMRmap',n_colors=3, desat=.9)\n",
    "      # keep color order consistent\n",
    "      pal = [pal[1], pal[0], pal[2]]\n",
    "      g = sns.FacetGrid(df, row=\"Temperature\", hue=\"Temperature\", aspect=9, height=1, palette=pal, row_order=conditions)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            ax.text(0, .2, f\"{label} ({len(df.loc[df['Temperature']==label])})\",\n",
    "                    fontweight=\"bold\", color=color,ha=\"left\", va=\"center\",\n",
    "                    transform=ax.transAxes)\n",
    "      g.map(label, \"Score\")\n",
    "       # Add vertical lines for mean and confidence intervals\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Temperature', order=conditions)\n",
    "      for ax, model in zip(g.axes.flat, ['Low', 'Mid', 'High']):\n",
    "            ax.axvline(mean_conf[mean_conf['Temperature'] == model]['median'].values[0], color='black', linestyle='--')\n",
    "      # Set the subplots to overlap\n",
    "      g.figure.subplots_adjust(hspace=-.5)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(50, 100))\n",
    "      \n",
    "      # Set a title for the figure\n",
    "      g.fig.suptitle(f\"CLAUDE - {df['Control'].unique()[0]}\", fontsize=20, y=1.05)\n",
    "      g.savefig('CLAUDE_DAT_temperature2_kde{}.png'.format(e), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Temperature', tvals_table=tvals, pvals_table=pvals, pal=[pal[1], pal[2], pal[0]],\n",
    "                     order=['Low', 'Mid', 'High'], save='CLAUDE_DAT_temperature3_{}.png'.format(e), large=(7, 3.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [results_df.loc[(results_df['Model']=='StableLM') &\n",
    "                              (results_df['Control']=='Original instructions')]]\n",
    "conditions = ['Low', 'Mid', 'High']\n",
    "list_of_dfs_normalized_filtered = [df.groupby('Temperature', as_index=False).apply(normalize_filter_std_n) for df in list_of_dfs]\n",
    "for e, df in enumerate(list_of_dfs_normalized_filtered):\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = sns.color_palette('CMRmap',n_colors=3, desat=.9)\n",
    "      # keep color order consistent\n",
    "      pal = [pal[1], pal[0], pal[2]]\n",
    "      g = sns.FacetGrid(df, row=\"Temperature\", hue=\"Temperature\", aspect=9, height=1, palette=pal, row_order=conditions)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            ax.text(0, .2, f\"{label} ({len(df.loc[df['Temperature']==label])})\",\n",
    "                    fontweight=\"bold\", color=color,ha=\"left\", va=\"center\",\n",
    "                    transform=ax.transAxes)\n",
    "      g.map(label, \"Score\")\n",
    "       # Add vertical lines for mean and confidence intervals\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Temperature', order=conditions)\n",
    "      for ax, model in zip(g.axes.flat, ['Low', 'Mid', 'High']):\n",
    "            ax.axvline(mean_conf[mean_conf['Temperature'] == model]['mean'].values[0], color='black', linestyle='--')\n",
    "      # Set the subplots to overlap\n",
    "      g.figure.subplots_adjust(hspace=-.5)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(30, 100))\n",
    "      \n",
    "      # Set a title for the figure\n",
    "      g.fig.suptitle(f\"Stable LM (Stability A.I.) - {df['Control'].unique()[0]}\", fontsize=20, y=1.05)\n",
    "      g.savefig('StableLM_temperature2_kde{}.png'.format(e), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Temperature', tvals_table=tvals, pvals_table=pvals, pal=[pal[1], pal[2], pal[0]],\n",
    "                     order=['Low', 'Mid', 'High'], save='StableLM_DAT_temperature2_{}.png'.format(e), large=(7, 3.5), xlim=(60, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [results_df.loc[(results_df['Model']=='Vicuna') &\n",
    "                              (results_df['Control']=='Original instructions')]]\n",
    "conditions = ['Low', 'Mid', 'High']\n",
    "list_of_dfs_normalized_filtered = [df.groupby('Temperature', as_index=False).apply(normalize_filter_std_n) for df in list_of_dfs]\n",
    "for e, df in enumerate(list_of_dfs_normalized_filtered):\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = sns.color_palette('CMRmap',n_colors=3, desat=.9)\n",
    "      # keep color order consistent\n",
    "      pal = [pal[1], pal[0], pal[2]]\n",
    "      g = sns.FacetGrid(df, row=\"Temperature\", hue=\"Temperature\", aspect=9, height=1, palette=pal, row_order=conditions)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "      # f\"{label} ({len(df.loc[df['Temperature']==label])})\"\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            ax.text(0, .2, f\"{label}\",\n",
    "                    fontweight=\"bold\", color=color,ha=\"left\", va=\"center\",\n",
    "                    transform=ax.transAxes)\n",
    "      g.map(label, \"Score\")\n",
    "       # Add vertical lines for mean and confidence intervals\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Temperature', order=conditions)\n",
    "      for ax, model in zip(g.axes.flat, ['Low', 'Mid', 'High']):\n",
    "            ax.axvline(mean_conf[mean_conf['Temperature'] == model]['median'].values[0], color='black', linestyle='--')\n",
    "      # Set the subplots to overlap\n",
    "      g.figure.subplots_adjust(hspace=-.5)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(60, 100))\n",
    "      \n",
    "      # Set a title for the figure\n",
    "      g.fig.suptitle(f\"gpt4 x Vicuna - {df['Control'].unique()[0]}\", fontsize=20, y=1.05)\n",
    "      g.savefig('Vicuna_DAT_temperature_kde{}.png'.format(e), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Temperature', tvals_table=tvals, pvals_table=pvals, pal=[pal[1], pal[2], pal[0]], order=['Low', 'Mid', 'High'],\n",
    "                     save='Vicuna_DAT_temperature_{}.png'.format(e), large=(7, 3.5), xlim=(60, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dfs = [results_df.loc[(results_df['Model']=='RedPajama') &\n",
    "                              (results_df['Control']=='Original instructions')],\n",
    "               results_df.loc[(results_df['Model']=='RedPajama') &\n",
    "                              (results_df['Control']=='Control')]]\n",
    "conditions = ['Low', 'Mid', 'High']\n",
    "list_of_dfs_normalized_filtered = [df.groupby('Temperature', as_index=False).apply(normalize_filter_std_n) for df in list_of_dfs]\n",
    "for e, df in enumerate(list_of_dfs_normalized_filtered):\n",
    "      # Initialize the FacetGrid object\n",
    "      pal = sns.color_palette('CMRmap',n_colors=3, desat=.9)\n",
    "      # keep color order consistent\n",
    "      pal = [pal[1], pal[0], pal[2]]\n",
    "      g = sns.FacetGrid(df, row=\"Temperature\", hue=\"Temperature\", aspect=9, height=1, palette=pal, row_order=conditions)\n",
    "\n",
    "      # Draw the densities in a few steps\n",
    "      g.map(sns.kdeplot, \"Score\",\n",
    "            bw_adjust=1, clip_on=False,\n",
    "            fill=True, alpha=1, linewidth=1.5)\n",
    "      g.map(sns.kdeplot, \"Score\", clip_on=False, color=\"w\", lw=2, bw_adjust=1)\n",
    "\n",
    "      # passing color=None to refline() uses the hue mapping\n",
    "      g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "      # f\"{label} ({len(df.loc[df['Temperature']==label])})\"\n",
    "      # Define and use a simple function to label the plot in axes coordinates\n",
    "      def label(x, color, label):\n",
    "            ax = plt.gca()\n",
    "            ax.text(0, .2, f\"{label}\",\n",
    "                    fontweight=\"bold\", color=color,ha=\"left\", va=\"center\",\n",
    "                    transform=ax.transAxes)\n",
    "      g.map(label, \"Score\")\n",
    "       # Add vertical lines for mean and confidence intervals\n",
    "      mean_conf, pvals, tvals = analyze_results(df, 'Temperature', order=conditions)\n",
    "      for ax, model in zip(g.axes.flat, ['Low', 'Mid', 'High']):\n",
    "            ax.axvline(mean_conf[mean_conf['Temperature'] == model]['median'].values[0], color='black', linestyle='--')\n",
    "      # Set the subplots to overlap\n",
    "      g.figure.subplots_adjust(hspace=-.5)\n",
    "\n",
    "      # Remove axes details that don't play well with overlap\n",
    "      g.set_titles(\"\")\n",
    "      g.set(yticks=[], ylabel=\"\")\n",
    "      g.despine(bottom=True, left=True)\n",
    "      g.set(xlim=(0, 100))\n",
    "      \n",
    "      # Set a title for the figure\n",
    "      g.fig.suptitle(f\"RedPajama - {df['Control'].unique()[0]}\", fontsize=20, y=1.05)\n",
    "      g.savefig('RedPajama_DAT_temperature_kde{}.png'.format(e), dpi=300)\n",
    "      create_heatmap(mean_conf, 'Temperature', tvals_table=tvals, pvals_table=pvals, pal=[pal[1], pal[2], pal[0]], order=['Low', 'Mid', 'High'],\n",
    "                     save='RedPajama_DAT_temperature_{}.png'.format(e), large=(7, 3.5), xlim=(60, 90))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "32df7692b2e9bcd60c85d28bd941a7a696d3465114b96c4326ab6093c57a7708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
